{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Raw Data\n",
    "\n",
    "This is necessary to try any subsection of this Notebook, so execute it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTED_MODES = np.arange(1, 33, dtype=int)\n",
    "TESTED_MODES_FULL_ORDER = np.arange(1, 100, 5, dtype=int)\n",
    "TRAIN_SPLIT = 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_file = np.load(\".data/Time_series_colisao.npz\")\n",
    "display(collision_file)\n",
    "spreading_file = np.load(\".data/Time_series_espalhamento.npz\")\n",
    "display(spreading_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_timesteps_raw = collision_file['TS']\n",
    "display(f\"Dimensions of the collision simulations: {collision_timesteps_raw.shape}\")\n",
    "display(f\"That is, {collision_timesteps_raw.shape[0]} simulations, with {collision_timesteps_raw.shape[1]} timesteps each, having {collision_timesteps_raw.shape[2]} components each.\")\n",
    "spreading_timesteps_raw = spreading_file['TS']\n",
    "display(f\"Dimensions of the spreading simulations: {spreading_timesteps_raw.shape}\")\n",
    "display(f\"That is, {spreading_timesteps_raw.shape[0]} simulations, with {spreading_timesteps_raw.shape[1]} timesteps each, having {spreading_timesteps_raw.shape[2]} components each.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision component-wise order reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering data\n",
    "\n",
    "We want to avoid mixing components in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_names = ['Diameter', 'Height', 'Kinetic Energy', 'Surface Energy', 'Dissipative Energy']\n",
    "collision = dict()\n",
    "for i, cn in enumerate(components_names):\n",
    "    cn_dict = {}\n",
    "    cn_dict['original_data'] = collision_timesteps_raw[:, :, i].T\n",
    "    # (n_simulations, timesteps) [RAW]\n",
    "    # (timesteps, n_simulations) [.T]\n",
    "    collision[cn] = cn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Firstly, we want to remove the \"temporal mean\", that is, the mean for each simulation of each component. After that, we can also scale the data so its standard variation is equal to 1:\n",
    "\n",
    "$$\\pmb{\\hat{X}}=\\sqrt{\\frac{1}{n}}\\left(\\pmb{X}-\\hat{x}1\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for key, obj in collision.items():\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(obj['original_data'])\n",
    "    display(f\"Asserting mean = 0 and std = 1 for component '{key}'\")\n",
    "    assert np.allclose(scaled_data.mean(axis=0), 0)\n",
    "    assert np.allclose(scaled_data.std(axis=0), 1)\n",
    "    display(\"Success!\")\n",
    "    obj['scaled_data'] = scaled_data\n",
    "    obj['scaler'] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for all the given modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "NUMBER_OF_MODES = TESTED_MODES.shape[0]\n",
    "for key, obj in collision.items():\n",
    "    number_of_timesteps = obj['scaled_data'].shape[0]\n",
    "    permutation_idx = np.random.permutation(number_of_timesteps)\n",
    "    training_size = int(TRAIN_SPLIT * number_of_timesteps)\n",
    "    training_idx = permutation_idx[:training_size]\n",
    "    testing_idx = permutation_idx[training_size:]\n",
    "    training_data = obj['original_data'][training_idx]\n",
    "    training_data_scaled = obj['scaled_data'][training_idx]\n",
    "    testing_data = obj['original_data'][testing_idx]\n",
    "    testing_data_scaled = obj['scaled_data'][testing_idx]\n",
    "    modes_mse = np.zeros((number_of_timesteps, NUMBER_OF_MODES))\n",
    "    modes_mae = np.zeros_like(modes_mse)\n",
    "    modes_mrae = np.zeros_like(modes_mse)\n",
    "    for i, mode in enumerate(TESTED_MODES):\n",
    "        # TRAINING DATA\n",
    "        pca = PCA(n_components=mode, random_state=42)\n",
    "        pca.fit(training_data_scaled)\n",
    "        reconstructed_training_scaled = pca.inverse_transform(pca.transform(training_data_scaled))\n",
    "        reconstructed_training = obj['scaler'].inverse_transform(reconstructed_training_scaled)\n",
    "        mse_training = np.mean((training_data - reconstructed_training)**2, axis=1)\n",
    "        mae_training = np.mean(np.abs(training_data - reconstructed_training), axis=1)\n",
    "        mrae_training = np.mean(np.abs(training_data - reconstructed_training) / np.abs(training_data), axis=1)\n",
    "        # TESTING DATA\n",
    "        reconstructed_testing_scaled = pca.inverse_transform(pca.transform(testing_data_scaled))\n",
    "        reconstructed_testing = obj['scaler'].inverse_transform(reconstructed_testing_scaled)\n",
    "        mse_testing = np.mean((testing_data - reconstructed_testing)**2, axis=1)\n",
    "        mae_testing = np.mean(np.abs(testing_data - reconstructed_testing), axis=1)\n",
    "        mrae_testing = np.mean(np.abs(testing_data - reconstructed_testing) / np.abs(testing_data), axis=1)\n",
    "        # STORING DATA\n",
    "        modes_mse[training_idx, i] = mse_training\n",
    "        modes_mae[training_idx, i] = mae_training\n",
    "        modes_mrae[training_idx, i] = mrae_training\n",
    "        modes_mse[testing_idx, i] = mse_testing\n",
    "        modes_mae[testing_idx, i] = mae_testing\n",
    "        modes_mrae[testing_idx, i] = mrae_testing\n",
    "    training_error_idx = pd.Index(training_idx, name='Timestep')\n",
    "    testing_error_idx = pd.Index(testing_idx, name='Timestep')\n",
    "    columns = pd.MultiIndex.from_product([TESTED_MODES, ['MSE', 'MAE', 'MRAE']], names=['Modes', 'Metric'])\n",
    "    training_error_data = np.zeros((training_error_idx.shape[0], NUMBER_OF_MODES * 3))\n",
    "    testing_error_data = np.zeros((testing_error_idx.shape[0], NUMBER_OF_MODES * 3))\n",
    "    training_error_data[:, ::3] = modes_mse[training_idx]\n",
    "    training_error_data[:, 1::3] = modes_mae[training_idx]\n",
    "    training_error_data[:, 2::3] = modes_mrae[training_idx]\n",
    "    testing_error_data[:, ::3] = modes_mse[testing_idx]\n",
    "    testing_error_data[:, 1::3] = modes_mae[testing_idx]\n",
    "    testing_error_data[:, 2::3] = modes_mrae[testing_idx]\n",
    "    training_error_df = pd.DataFrame(training_error_data, columns=columns, index=training_error_idx).sort_index()\n",
    "    testing_error_df = pd.DataFrame(testing_error_data, columns=columns, index=testing_error_idx).sort_index()\n",
    "    obj['permutation_idx'] = permutation_idx\n",
    "    obj['training_idx'] = training_idx\n",
    "    obj['testing_idx'] = testing_idx\n",
    "    obj['training_error'] = training_error_df\n",
    "    obj['testing_error'] = testing_error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing these errors in graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "ax.set_title(\"Mean relative absolute error for collision simulation components\")\n",
    "ax.set_xlabel(\"Number of modes\")\n",
    "ax.set_ylabel(\"Mean relative absolute error (MARE)\")\n",
    "\n",
    "for key, obj in collision.items():\n",
    "    obj['training_error'].loc[:, (slice(None), 'MRAE')].mean().unstack().plot(ax=ax, linestyle='--', alpha=0.5)\n",
    "    obj['testing_error'].loc[:, (slice(None), 'MRAE')].mean().unstack().plot(ax=ax, linestyle='-')\n",
    "\n",
    "training_legend = [f\"{key} (training)\" for key in collision.keys()]\n",
    "testing_legend = [f\"{key} (testing)\" for key in collision.keys()]\n",
    "legend = [''] * (len(training_legend) + len(testing_legend))\n",
    "legend[::2] = training_legend\n",
    "legend[1::2] = testing_legend\n",
    "ax.legend(legend)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\".results/pca_error_modes_collision.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spreading component-wise order reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering data\n",
    "\n",
    "We want to avoid mixing components in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreading_components_names = ['Diameter', 'Kinetic Energy', 'Surface Energy', 'Dissipative Energy']\n",
    "spreading = dict()\n",
    "for i, cn in enumerate(spreading_components_names):\n",
    "    cn_dict = {}\n",
    "    cn_dict['original_data'] = spreading_timesteps_raw[:, :, i].T\n",
    "    # (n_simulations, timesteps) [RAW]\n",
    "    # (timesteps, n_simulations) [.T]\n",
    "    spreading[cn] = cn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Firstly, we want to remove the \"temporal mean\", that is, the mean for each simulation of each component. After that, we can also scale the data so its standard variation is equal to 1:\n",
    "\n",
    "$$\\pmb{\\hat{X}}=\\sqrt{\\frac{1}{n}}\\left(\\pmb{X}-\\hat{x}1\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for key, obj in spreading.items():\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(obj['original_data'])\n",
    "    display(f\"Asserting mean = 0 and std = 1 for component '{key}'\")\n",
    "    assert np.allclose(scaled_data.mean(axis=0), 0)\n",
    "    assert np.allclose(scaled_data.std(axis=0), 1)\n",
    "    display(\"Success!\")\n",
    "    obj['scaled_data'] = scaled_data\n",
    "    obj['scaler'] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for all the given modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "NUMBER_OF_MODES = TESTED_MODES.shape[0]\n",
    "for key, obj in spreading.items():\n",
    "    number_of_timesteps = obj['scaled_data'].shape[0]\n",
    "    permutation_idx = np.random.permutation(number_of_timesteps)\n",
    "    training_size = int(TRAIN_SPLIT * number_of_timesteps)\n",
    "    training_idx = permutation_idx[:training_size]\n",
    "    testing_idx = permutation_idx[training_size:]\n",
    "    training_data = obj['original_data'][training_idx]\n",
    "    training_data_scaled = obj['scaled_data'][training_idx]\n",
    "    testing_data = obj['original_data'][testing_idx]\n",
    "    testing_data_scaled = obj['scaled_data'][testing_idx]\n",
    "    modes_mse = np.zeros((number_of_timesteps, NUMBER_OF_MODES))\n",
    "    modes_mae = np.zeros_like(modes_mse)\n",
    "    modes_mrae = np.zeros_like(modes_mse)\n",
    "    for i, mode in enumerate(TESTED_MODES):\n",
    "        # TRAINING DATA\n",
    "        pca = PCA(n_components=mode)\n",
    "        pca.fit(training_data_scaled)\n",
    "        reconstructed_training_scaled = pca.inverse_transform(pca.transform(training_data_scaled))\n",
    "        reconstructed_training = obj['scaler'].inverse_transform(reconstructed_training_scaled)\n",
    "        mse_training = np.mean((training_data - reconstructed_training)**2, axis=1)\n",
    "        mae_training = np.mean(np.abs(training_data - reconstructed_training), axis=1)\n",
    "        mrae_training = np.mean(np.abs(training_data - reconstructed_training) / np.abs(training_data), axis=1)\n",
    "        # TESTING DATA\n",
    "        reconstructed_testing_scaled = pca.inverse_transform(pca.transform(testing_data_scaled))\n",
    "        reconstructed_testing = obj['scaler'].inverse_transform(reconstructed_testing_scaled)\n",
    "        mse_testing = np.mean((testing_data - reconstructed_testing)**2, axis=1)\n",
    "        mae_testing = np.mean(np.abs(testing_data - reconstructed_testing), axis=1)\n",
    "        mrae_testing = np.mean(np.abs(testing_data - reconstructed_testing) / np.abs(testing_data), axis=1)\n",
    "        # STORING DATA\n",
    "        modes_mse[training_idx, i] = mse_training\n",
    "        modes_mae[training_idx, i] = mae_training\n",
    "        modes_mrae[training_idx, i] = mrae_training\n",
    "        modes_mse[testing_idx, i] = mse_testing\n",
    "        modes_mae[testing_idx, i] = mae_testing\n",
    "        modes_mrae[testing_idx, i] = mrae_testing\n",
    "    training_error_idx = pd.Index(training_idx, name='Timestep')\n",
    "    testing_error_idx = pd.Index(testing_idx, name='Timestep')\n",
    "    columns = pd.MultiIndex.from_product([TESTED_MODES, ['MSE', 'MAE', 'MRAE']], names=['Modes', 'Metric'])\n",
    "    training_error_data = np.zeros((training_error_idx.shape[0], NUMBER_OF_MODES * 3))\n",
    "    testing_error_data = np.zeros((testing_error_idx.shape[0], NUMBER_OF_MODES * 3))\n",
    "    training_error_data[:, ::3] = modes_mse[training_idx]\n",
    "    training_error_data[:, 1::3] = modes_mae[training_idx]\n",
    "    training_error_data[:, 2::3] = modes_mrae[training_idx]\n",
    "    testing_error_data[:, ::3] = modes_mse[testing_idx]\n",
    "    testing_error_data[:, 1::3] = modes_mae[testing_idx]\n",
    "    testing_error_data[:, 2::3] = modes_mrae[testing_idx]\n",
    "    training_error_df = pd.DataFrame(training_error_data, columns=columns, index=training_error_idx).sort_index()\n",
    "    testing_error_df = pd.DataFrame(testing_error_data, columns=columns, index=testing_error_idx).sort_index()\n",
    "    obj['permutation_idx'] = permutation_idx\n",
    "    obj['training_idx'] = training_idx\n",
    "    obj['testing_idx'] = testing_idx\n",
    "    obj['training_error'] = training_error_df\n",
    "    obj['testing_error'] = testing_error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing these errors in graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "ax.set_title(\"Mean relative absolute error for spreading simulation components\")\n",
    "ax.set_xlabel(\"Number of modes\")\n",
    "ax.set_ylabel(\"Mean relative absolute error (MARE)\")\n",
    "\n",
    "for key, obj in spreading.items():\n",
    "    obj['training_error'].loc[:, (slice(None), 'MRAE')].mean().unstack().plot(ax=ax, linestyle='--', alpha=0.5)\n",
    "    obj['testing_error'].loc[:, (slice(None), 'MRAE')].mean().unstack().plot(ax=ax, linestyle='-')\n",
    "\n",
    "training_legend = [f\"{key} (training)\" for key in spreading.keys()]\n",
    "testing_legend = [f\"{key} (testing)\" for key in spreading.keys()]\n",
    "legend = [''] * (len(training_legend) + len(testing_legend))\n",
    "legend[::2] = training_legend\n",
    "legend[1::2] = testing_legend\n",
    "ax.legend(legend)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\".results/pca_error_modes_spreading.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision full order reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering data and rescaling energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_timesteps_components_last = np.transpose(collision_timesteps_raw, (1, 0, 2))\n",
    "display(f\"Shape after transpose is: {collision_timesteps_components_last.shape}\")\n",
    "# We want to rescale the energies (3rd, 4th and 5th components) in a way that its sum is 1\n",
    "# By doing this, we can rule out the magnitude effect of the energies\n",
    "# First, let's save these magnitudes\n",
    "# collision_timesteps_components_last_energies = collision_timesteps_components_last[:, :, 2:].sum(axis=-1)\n",
    "# # Now, let's divide the energies by their sum\n",
    "# collision_timesteps_components_last[:, :, 2:] = (\n",
    "#     collision_timesteps_components_last[:, :, 2:] /\n",
    "#     collision_timesteps_components_last_energies[:, :, np.newaxis]\n",
    "# )\n",
    "# Flattening 2nd and 3rd dimensions\n",
    "collision_timesteps_components_last = (\n",
    "    collision_timesteps_components_last\n",
    "    .reshape(collision_timesteps_components_last.shape[0], -1)\n",
    ")\n",
    "display(f\"Shape after flattening is: {collision_timesteps_components_last.shape}\")\n",
    "collision_full = {}\n",
    "collision_full['original_data'] = collision_timesteps_components_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(collision_full['original_data'])\n",
    "display(f\"Asserting mean = 0 and std = 1 for every column\")\n",
    "assert np.allclose(scaled_data.mean(axis=0), 0)\n",
    "assert np.allclose(scaled_data.std(axis=0), 1)\n",
    "display(\"Success!\")\n",
    "collision_full['scaled_data'] = scaled_data\n",
    "collision_full['scaler'] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing every mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "NUMBER_OF_MODES = TESTED_MODES_FULL_ORDER.shape[0]\n",
    "number_of_timesteps = collision_full['scaled_data'].shape[0]\n",
    "permutation_idx = np.random.permutation(number_of_timesteps)\n",
    "training_size = int(TRAIN_SPLIT * number_of_timesteps)\n",
    "training_idx = permutation_idx[:training_size]\n",
    "testing_idx = permutation_idx[training_size:]\n",
    "training_data = collision_full['original_data'][training_idx]\n",
    "training_data_scaled = collision_full['scaled_data'][training_idx]\n",
    "testing_data = collision_full['original_data'][testing_idx]\n",
    "testing_data_scaled = collision_full['scaled_data'][testing_idx]\n",
    "modes_mse = np.zeros((number_of_timesteps, NUMBER_OF_MODES))\n",
    "modes_mae = np.zeros_like(modes_mse)\n",
    "modes_mrae = np.zeros_like(modes_mse)\n",
    "modes_mse_no_mean = np.zeros_like(modes_mse)\n",
    "modes_mae_no_mean = np.zeros_like(modes_mse)\n",
    "modes_mrae_no_mean = np.zeros_like(modes_mse)\n",
    "for i, mode in enumerate(TESTED_MODES_FULL_ORDER):\n",
    "    # TRAINING DATA\n",
    "    pca = PCA(n_components=mode, random_state=42)\n",
    "    pca.fit(training_data_scaled)\n",
    "    # Example of PCA without removing the mean\n",
    "    u_train, s_train, v_train = np.linalg.svd(training_data, full_matrices=False)\n",
    "    reconstructed_training_no_mean = u_train[:, :mode] @ np.diag(s_train[:mode]) @ v_train[:mode, :]\n",
    "    reconstructed_training_scaled = pca.inverse_transform(pca.transform(training_data_scaled))\n",
    "    reconstructed_training = collision_full['scaler'].inverse_transform(reconstructed_training_scaled)\n",
    "    mse_training = np.mean((training_data - reconstructed_training)**2, axis=1)\n",
    "    mae_training = np.mean(np.abs(training_data - reconstructed_training), axis=1)\n",
    "    mrae_training = np.mean(np.abs(training_data - reconstructed_training) / np.abs(training_data), axis=1)\n",
    "    mse_training_no_mean = np.mean((training_data - reconstructed_training_no_mean)**2, axis=1)\n",
    "    mae_training_no_mean = np.mean(np.abs(training_data - reconstructed_training_no_mean), axis=1)\n",
    "    mrae_training_no_mean = np.mean(np.abs(training_data - reconstructed_training_no_mean) / np.abs(training_data), axis=1)\n",
    "    # TESTING DATA\n",
    "    reconstructed_testing_scaled = pca.inverse_transform(pca.transform(testing_data_scaled))\n",
    "    reconstructed_testing = collision_full['scaler'].inverse_transform(reconstructed_testing_scaled)\n",
    "    reconstructed_testing_no_mean = (testing_data @ v_train[:mode, :].T) @ v_train[:mode, :]\n",
    "    mse_testing = np.mean((testing_data - reconstructed_testing)**2, axis=1)\n",
    "    mae_testing = np.mean(np.abs(testing_data - reconstructed_testing), axis=1)\n",
    "    mrae_testing = np.mean(np.abs(testing_data - reconstructed_testing) / np.abs(testing_data), axis=1)\n",
    "    mse_testing_no_mean = np.mean((testing_data - reconstructed_testing_no_mean)**2, axis=1)\n",
    "    mae_testing_no_mean = np.mean(np.abs(testing_data - reconstructed_testing_no_mean), axis=1)\n",
    "    mrae_testing_no_mean = np.mean(np.abs(testing_data - reconstructed_testing_no_mean) / np.abs(testing_data), axis=1)\n",
    "    # STORING DATA\n",
    "    modes_mse[training_idx, i] = mse_training\n",
    "    modes_mae[training_idx, i] = mae_training\n",
    "    modes_mrae[training_idx, i] = mrae_training\n",
    "    modes_mse[testing_idx, i] = mse_testing\n",
    "    modes_mae[testing_idx, i] = mae_testing\n",
    "    modes_mrae[testing_idx, i] = mrae_testing\n",
    "    modes_mse_no_mean[training_idx, i] = mse_training_no_mean\n",
    "    modes_mae_no_mean[training_idx, i] = mae_training_no_mean\n",
    "    modes_mrae_no_mean[training_idx, i] = mrae_training_no_mean\n",
    "    modes_mse_no_mean[testing_idx, i] = mse_testing_no_mean\n",
    "    modes_mae_no_mean[testing_idx, i] = mae_testing_no_mean\n",
    "    modes_mrae_no_mean[testing_idx, i] = mrae_testing_no_mean\n",
    "training_error_idx = pd.Index(training_idx, name='Timestep')\n",
    "testing_error_idx = pd.Index(testing_idx, name='Timestep')\n",
    "columns = pd.MultiIndex.from_product([TESTED_MODES_FULL_ORDER, ['SKLearn PCA', 'No mean removing'], ['MSE', 'MAE', 'MRAE']], names=['Modes', 'Treatment', 'Metric'])\n",
    "training_error_data = np.zeros((training_error_idx.shape[0], NUMBER_OF_MODES * 3 * 2))\n",
    "testing_error_data = np.zeros((testing_error_idx.shape[0], NUMBER_OF_MODES * 3 * 2))\n",
    "training_error_data[:, ::6] = modes_mse[training_idx]\n",
    "training_error_data[:, 1::6] = modes_mae[training_idx]\n",
    "training_error_data[:, 2::6] = modes_mrae[training_idx]\n",
    "training_error_data[:, 3::6] = modes_mse_no_mean[training_idx]\n",
    "training_error_data[:, 4::6] = modes_mae_no_mean[training_idx]\n",
    "training_error_data[:, 5::6] = modes_mrae_no_mean[training_idx]\n",
    "testing_error_data[:, ::6] = modes_mse[testing_idx]\n",
    "testing_error_data[:, 1::6] = modes_mae[testing_idx]\n",
    "testing_error_data[:, 2::6] = modes_mrae[testing_idx]\n",
    "testing_error_data[:, 3::6] = modes_mse_no_mean[testing_idx]\n",
    "testing_error_data[:, 4::6] = modes_mae_no_mean[testing_idx]\n",
    "testing_error_data[:, 5::6] = modes_mrae_no_mean[testing_idx]\n",
    "training_error_df = pd.DataFrame(training_error_data, columns=columns, index=training_error_idx).sort_index()\n",
    "testing_error_df = pd.DataFrame(testing_error_data, columns=columns, index=testing_error_idx).sort_index()\n",
    "collision_full['permutation_idx'] = permutation_idx\n",
    "collision_full['training_idx'] = training_idx\n",
    "collision_full['testing_idx'] = testing_idx\n",
    "collision_full['training_error'] = training_error_df\n",
    "collision_full['testing_error'] = testing_error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "ax.set_title(\"Mean relative absolute error in collision simulation full order reduction\")\n",
    "ax.set_xlabel(\"Number of modes\")\n",
    "ax.set_ylabel(\"Mean relative absolute error (MRAE)\")\n",
    "\n",
    "(\n",
    "    collision_full['training_error']\n",
    "    .loc[:, (slice(None), slice(None), 'MRAE')]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .unstack()\n",
    "    .plot(ax=ax, linestyle='--', alpha=0.5)\n",
    ")\n",
    "(\n",
    "    collision_full['testing_error']\n",
    "    .loc[:, (slice(None), slice(None), 'MRAE')]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .unstack()\n",
    "    .plot(ax=ax, linestyle='-')\n",
    ")\n",
    "\n",
    "ax.legend([\n",
    "    'Training (SVD without data treatment)',\n",
    "    'Training (SKLearn PCA)',\n",
    "    'Testing (SVD without data treatment)',\n",
    "    'Testing (SKLearn PCA)'\n",
    "])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\".results/pca_error_modes_collision_full.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spreading full order reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering data and rescaling energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreading_timesteps_components_last = np.transpose(spreading_timesteps_raw, (1, 0, 2))\n",
    "display(f\"Shape after transpose is: {spreading_timesteps_components_last.shape}\")\n",
    "# We want to rescale the energies (2nd, 3rd and 4th components) in a way that its sum is 1\n",
    "# By doing this, we can rule out the magnitude effect of the energies\n",
    "# First, let's save these magnitudes\n",
    "# spreading_timesteps_components_last_energies = spreading_timesteps_components_last[:, :, 1:].sum(axis=-1)\n",
    "# # Now, let's divide the energies by their sum\n",
    "# spreading_timesteps_components_last[:, :, 1:] = (\n",
    "#     spreading_timesteps_components_last[:, :, 1:] /\n",
    "#     spreading_timesteps_components_last_energies[:, :, np.newaxis]\n",
    "# )\n",
    "# Flattening 2nd and 3rd dimensions\n",
    "spreading_timesteps_components_last = (\n",
    "    spreading_timesteps_components_last\n",
    "    .reshape(spreading_timesteps_components_last.shape[0], -1)\n",
    ")\n",
    "display(f\"Shape after flattening is: {spreading_timesteps_components_last.shape}\")\n",
    "spreading_full = {}\n",
    "spreading_full['original_data'] = spreading_timesteps_components_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(spreading_full['original_data'])\n",
    "display(f\"Asserting mean = 0 and std = 1 for every column\")\n",
    "assert np.allclose(scaled_data.mean(axis=0), 0)\n",
    "assert np.allclose(scaled_data.std(axis=0), 1)\n",
    "display(\"Success!\")\n",
    "spreading_full['scaled_data'] = scaled_data\n",
    "spreading_full['scaler'] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing every mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "NUMBER_OF_MODES = TESTED_MODES_FULL_ORDER.shape[0]\n",
    "number_of_timesteps = spreading_full['scaled_data'].shape[0]\n",
    "permutation_idx = np.random.permutation(number_of_timesteps)\n",
    "training_size = int(TRAIN_SPLIT * number_of_timesteps)\n",
    "training_idx = permutation_idx[:training_size]\n",
    "testing_idx = permutation_idx[training_size:]\n",
    "training_data = spreading_full['original_data'][training_idx]\n",
    "training_data_scaled = spreading_full['scaled_data'][training_idx]\n",
    "testing_data = spreading_full['original_data'][testing_idx]\n",
    "testing_data_scaled = spreading_full['scaled_data'][testing_idx]\n",
    "modes_mse = np.zeros((number_of_timesteps, NUMBER_OF_MODES))\n",
    "modes_mae = np.zeros_like(modes_mse)\n",
    "modes_mrae = np.zeros_like(modes_mse)\n",
    "for i, mode in enumerate(TESTED_MODES_FULL_ORDER):\n",
    "    # TRAINING DATA\n",
    "    pca = PCA(n_components=mode, random_state=42)\n",
    "    pca.fit(training_data_scaled)\n",
    "    reconstructed_training_scaled = pca.inverse_transform(pca.transform(training_data_scaled))\n",
    "    reconstructed_training = spreading_full['scaler'].inverse_transform(reconstructed_training_scaled)\n",
    "    mse_training = np.mean((training_data - reconstructed_training)**2, axis=1)\n",
    "    mae_training = np.mean(np.abs(training_data - reconstructed_training), axis=1)\n",
    "    mrae_training = np.mean(np.abs(training_data - reconstructed_training) / np.abs(training_data), axis=1)\n",
    "    # TESTING DATA\n",
    "    reconstructed_testing_scaled = pca.inverse_transform(pca.transform(testing_data_scaled))\n",
    "    reconstructed_testing = spreading_full['scaler'].inverse_transform(reconstructed_testing_scaled)\n",
    "    mse_testing = np.mean((testing_data - reconstructed_testing)**2, axis=1)\n",
    "    mae_testing = np.mean(np.abs(testing_data - reconstructed_testing), axis=1)\n",
    "    mrae_testing = np.mean(np.abs(testing_data - reconstructed_testing) / np.abs(testing_data), axis=1)\n",
    "    # STORING DATA\n",
    "    modes_mse[training_idx, i] = mse_training\n",
    "    modes_mae[training_idx, i] = mae_training\n",
    "    modes_mrae[training_idx, i] = mrae_training\n",
    "    modes_mse[testing_idx, i] = mse_testing\n",
    "    modes_mae[testing_idx, i] = mae_testing\n",
    "    modes_mrae[testing_idx, i] = mrae_testing\n",
    "training_error_idx = pd.Index(training_idx, name='Timestep')\n",
    "testing_error_idx = pd.Index(testing_idx, name='Timestep')\n",
    "columns = pd.MultiIndex.from_product([TESTED_MODES_FULL_ORDER, ['MSE', 'MAE', 'MRAE']], names=['Modes', 'Metric'])\n",
    "training_error_data = np.zeros((training_error_idx.shape[0], NUMBER_OF_MODES * 3))\n",
    "testing_error_data = np.zeros((testing_error_idx.shape[0], NUMBER_OF_MODES * 3))\n",
    "training_error_data[:, ::3] = modes_mse[training_idx]\n",
    "training_error_data[:, 1::3] = modes_mae[training_idx]\n",
    "training_error_data[:, 2::3] = modes_mrae[training_idx]\n",
    "testing_error_data[:, ::3] = modes_mse[testing_idx]\n",
    "testing_error_data[:, 1::3] = modes_mae[testing_idx]\n",
    "testing_error_data[:, 2::3] = modes_mrae[testing_idx]\n",
    "training_error_df = pd.DataFrame(training_error_data, columns=columns, index=training_error_idx).sort_index()\n",
    "testing_error_df = pd.DataFrame(testing_error_data, columns=columns, index=testing_error_idx).sort_index()\n",
    "spreading_full['permutation_idx'] = permutation_idx\n",
    "spreading_full['training_idx'] = training_idx\n",
    "spreading_full['testing_idx'] = testing_idx\n",
    "spreading_full['training_error'] = training_error_df\n",
    "spreading_full['testing_error'] = testing_error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "ax.set_title(\"Mean relative absolute error in spreading simulation full order reduction\")\n",
    "ax.set_xlabel(\"Number of modes\")\n",
    "ax.set_ylabel(\"Mean relative absolute error (MRAE)\")\n",
    "\n",
    "spreading_full['training_error'].loc[:, (slice(None), 'MRAE')].mean().unstack().plot(ax=ax, linestyle='--', alpha=0.5)\n",
    "spreading_full['testing_error'].loc[:, (slice(None), 'MRAE')].mean().unstack().plot(ax=ax, linestyle='-')\n",
    "\n",
    "ax.legend(['Training', 'Testing'])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\".results/pca_error_modes_spreading_full.png\", dpi=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
